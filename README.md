# Detection of Interactions Software for High-throughput Analysis

An automated tool to detect and analyze yeast-based assays to learn more about transcriptional regulation in immune
responses and cancer.

The current version uses segmentation model trained on a dataset generated by my manual colony extraction algorithm. The dataset was generated by running different configuration of the manual algorithm and randomly sampling patches from the output images. I created a tool to either include or reject those random samples and populate the dataset.

## Instructions

#### This software is mainly for processing large batches of images on a high performance server like the SCC at BU.

### Environment setup and Installation

The environment setup takes 5-10 and software installation takes ~1 minute with high-speed internet.
The software requires a GPU to function properly. Setup CUDA toolkit and Tensorflow before setting up the software.

```
conda create -n disha pyside2 python=3.10
conda activate disha
conda install -c conda-forge cudatoolkit=11.8.0
python3 -m pip install nvidia-cudnn-cu11==8.6.0.163 tensorflow==2.9.1
mkdir -p $CONDA_PREFIX/etc/conda/activate.d
echo 'CUDNN_PATH=$(dirname $(python -c "import nvidia.cudnn;print(nvidia.cudnn.__file__)"))' >> $CONDA_PREFIX/etc/conda/activate.d/env_vars.sh
echo 'export LD_LIBRARY_PATH=$LD_LIBRARY_PATH:$CONDA_PREFIX/lib/:$CUDNN_PATH/lib' >> $CONDA_PREFIX/etc/conda/activate.d/env_vars.sh
source $CONDA_PREFIX/etc/conda/activate.d/env_vars.sh
# Verify install:
python3 -c "import tensorflow as tf; print(tf.config.list_physical_devices('GPU'))"

# Clone Repository
git clone https://github.com/mahir1010/D.I.S.H.A
cd disha
python -m pip install build --upgrade
python -m build
python -m pip install ./dist/<replace with .whl file name>
```
This will create two entry points for the software ```disha-verify``` to verify folder structure and ```disha-analyzer``` that processes the data.



### Segmentation Model Weights and sample data

We provide our model weights and sample data [here](https://drive.google.com/drive/folders/1oZFCNsfJE_BUgq3KdY4buXx3_B-0tXht?usp=share_link). Users can also use their own model.

### Folder Structure

1. Create a root folder that will contain all the experiments.
2. Each experiment should have their own folder containing all images and an excel file containing details about coordinates and transcription factor pairs.
3. Activate conda environment and execute ```disha-verify <path to experiment fodler>``` to verfiy files.
4. Execute ```disha-analyzer <path to root experiment folder> <path to model weights> <batch size>``` to process the data.
5. The software will crawl all the subfolders and execute the processing pipeline if it does not contain the 'output' folder.
6. The output files will have the extension ```.dhy1h```. You will need to use <a href = "https://mahir1010.github.io/DHY1H-Viewer/">DHY1H Viewer</a> for visualizing the data.

## Results
### Raw Image
<img style="width:50%" src="https://raw.githubusercontent.com/mahir1010/Heterodimer-Y1H-Analysis/main/docs/example_raw.JPG">

### Initial boundary clipping and historgram projection
<img style="width:50%" src="https://raw.githubusercontent.com/mahir1010/Heterodimer-Y1H-Analysis/main/docs/example_trim.png">

### Grid generation using peak detection
<img style="width:50%" src="https://raw.githubusercontent.com/mahir1010/Heterodimer-Y1H-Analysis/main/docs/example_grid.png">

### Segmentation
<img style="width:50%" src="https://raw.githubusercontent.com/mahir1010/Heterodimer-Y1H-Analysis/main/docs/example_binary.png">
